{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T19:22:22.692544Z",
     "start_time": "2025-05-09T19:22:20.074003Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-09T20:28:21.191542Z",
     "iopub.status.busy": "2025-05-09T20:28:21.191033Z",
     "iopub.status.idle": "2025-05-09T20:29:32.048111Z",
     "shell.execute_reply": "2025-05-09T20:29:32.047326Z",
     "shell.execute_reply.started": "2025-05-09T20:28:21.191521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m^C\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/axr/prog/multimedia_labs/env/lib/python3.12/site-packages/pip/__main__.py\", line 24, in <module>\n",
      "    sys.exit(_main())\n",
      "             ^^^^^^^\n",
      "  File \"/home/axr/prog/multimedia_labs/env/lib/python3.12/site-packages/pip/_internal/cli/main.py\", line 79, in main\n",
      "    return command.main(cmd_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/axr/prog/multimedia_labs/env/lib/python3.12/site-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
      "    with self.main_context():\n",
      "  File \"/usr/lib/python3.12/contextlib.py\", line 144, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/home/axr/prog/multimedia_labs/env/lib/python3.12/site-packages/pip/_internal/cli/command_context.py\", line 19, in main_context\n",
      "    with self._main_context:\n",
      "  File \"/usr/lib/python3.12/contextlib.py\", line 610, in __exit__\n",
      "    raise exc_details[1]\n",
      "  File \"/usr/lib/python3.12/contextlib.py\", line 595, in __exit__\n",
      "    if cb(*exc_details):\n",
      "       ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/contextlib.py\", line 144, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/home/axr/prog/multimedia_labs/env/lib/python3.12/site-packages/pip/_internal/utils/temp_dir.py\", line 42, in global_tempdir_manager\n",
      "    with ExitStack() as stack:\n",
      "  File \"/usr/lib/python3.12/contextlib.py\", line 610, in __exit__\n",
      "    raise exc_details[1]\n",
      "  File \"/usr/lib/python3.12/contextlib.py\", line 595, in __exit__\n",
      "    if cb(*exc_details):\n",
      "       ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/axr/prog/multimedia_labs/env/lib/python3.12/site-packages/pip/_internal/utils/temp_dir.py\", line 169, in __exit__\n",
      "    self.cleanup()\n",
      "  File \"/home/axr/prog/multimedia_labs/env/lib/python3.12/site-packages/pip/_internal/utils/temp_dir.py\", line 212, in cleanup\n",
      "    rmtree(self._path, ignore_errors=False)\n",
      "  File \"/home/axr/prog/multimedia_labs/env/lib/python3.12/site-packages/pip/_vendor/tenacity/__init__.py\", line 291, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/axr/prog/multimedia_labs/env/lib/python3.12/site-packages/pip/_vendor/tenacity/__init__.py\", line 381, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/axr/prog/multimedia_labs/env/lib/python3.12/site-packages/pip/_vendor/tenacity/__init__.py\", line 316, in iter\n",
      "    return fut.result()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/home/axr/prog/multimedia_labs/env/lib/python3.12/site-packages/pip/_vendor/tenacity/__init__.py\", line 384, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/axr/prog/multimedia_labs/env/lib/python3.12/site-packages/pip/_internal/utils/misc.py\", line 144, in rmtree\n",
      "    shutil.rmtree(dir, onexc=handler)  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/shutil.py\", line 785, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onexc)\n",
      "  File \"/usr/lib/python3.12/shutil.py\", line 715, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "KeyboardInterrupt\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch segmentation-models-pytorch timm torchmetrics albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598d47fe1b9b59eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T19:22:44.071116Z",
     "start_time": "2025-05-09T19:22:39.617303Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-09T20:31:58.970324Z",
     "iopub.status.busy": "2025-05-09T20:31:58.970052Z",
     "iopub.status.idle": "2025-05-09T20:32:04.800459Z",
     "shell.execute_reply": "2025-05-09T20:32:04.799683Z",
     "shell.execute_reply.started": "2025-05-09T20:31:58.970303Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import zipfile, os, shutil, random, pathlib\n",
    "import pathlib, random, zipfile, os\n",
    "import pandas as pd, numpy as np, torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.dataset import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy, MulticlassF1Score, MulticlassConfusionMatrix\n",
    ")\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "SEED       = 42\n",
    "IMG_SIZE   = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_BL  = 10\n",
    "EPOCHS_IMP = 20\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "DATA_DIR = pathlib.Path(\"/kaggle/input/realwaste/realwaste-main/RealWaste\")\n",
    "all_images = []\n",
    "for class_idx, class_name in enumerate(sorted(p.name for p in DATA_DIR.iterdir())):\n",
    "    for img_path in (DATA_DIR / class_name).glob(\"*\"):\n",
    "        all_images.append((img_path, class_idx, class_name))\n",
    "\n",
    "dataframe = pd.DataFrame(all_images, columns=[\"path\", \"label\", \"class\"])\n",
    "train_df, tmp_df = train_test_split(\n",
    "    dataframe, test_size=0.30, random_state=42, stratify=dataframe[\"label\"]\n",
    ")\n",
    "val_df, test_df  = train_test_split(\n",
    "    tmp_df, test_size=0.50, random_state=42, stratify=tmp_df[\"label\"]\n",
    ")\n",
    "print(f\"fit_data {len(train_df)}, val {len(val_df)}, eval_data {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82adfc5c5d2c0669",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T19:23:25.216841Z",
     "start_time": "2025-05-09T19:23:25.212857Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-09T20:32:10.014159Z",
     "iopub.status.busy": "2025-05-09T20:32:10.013360Z",
     "iopub.status.idle": "2025-05-09T20:32:10.019300Z",
     "shell.execute_reply": "2025-05-09T20:32:10.018396Z",
     "shell.execute_reply.started": "2025-05-09T20:32:10.014133Z"
    }
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "import segmentation_models_pytorch as smp\n",
    "print(list(k for k in smp.encoders.encoders.keys()\n",
    "           if k.startswith(\"timm-vit\") )[:5])\n",
    "print([k for k in smp.encoders.encoders if \"vit\" in k][:10])\n",
    "import segmentation_models_pytorch as smp\n",
    "print([k for k in smp.encoders.encoders if k.startswith(\"timm\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc07f4809e3f7f07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T19:28:42.180504Z",
     "start_time": "2025-05-09T19:28:42.175074Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-09T20:32:11.656820Z",
     "iopub.status.busy": "2025-05-09T20:32:11.656214Z",
     "iopub.status.idle": "2025-05-09T20:32:11.661823Z",
     "shell.execute_reply": "2025-05-09T20:32:11.660983Z",
     "shell.execute_reply.started": "2025-05-09T20:32:11.656793Z"
    }
   },
   "outputs": [],
   "source": [
    "train_tfms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std =[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE + 32),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std =[0.229,0.224,0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96d261955f1c78e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T19:28:44.309352Z",
     "start_time": "2025-05-09T19:28:44.303188Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-09T20:32:13.403072Z",
     "iopub.status.busy": "2025-05-09T20:32:13.402784Z",
     "iopub.status.idle": "2025-05-09T20:32:13.410526Z",
     "shell.execute_reply": "2025-05-09T20:32:13.409936Z",
     "shell.execute_reply.started": "2025-05-09T20:32:13.403052Z"
    }
   },
   "outputs": [],
   "source": [
    "class WasteDataset(Dataset):\n",
    "    def __init__(self, frame, tfm):\n",
    "        self.f, self.tfm = frame.reset_index(drop=True), tfm\n",
    "    def __len__(self): return len(self.f)\n",
    "    def __getitem__(self, i):\n",
    "        img = Image.open(self.f.loc[i,\"path\"]).convert(\"RGB\")\n",
    "        return self.tfm(img), self.f.loc[i,\"label\"]\n",
    "\n",
    "train_dl = DataLoader(WasteDataset(train_df, train_tfms),\n",
    "                      batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      num_workers=0, pin_memory=True)\n",
    "val_dl   = DataLoader(WasteDataset(val_df, val_tfms),\n",
    "                      batch_size=BATCH_SIZE, num_workers=0, pin_memory=True)\n",
    "test_dl  = DataLoader(WasteDataset(test_df, val_tfms),\n",
    "                      batch_size=BATCH_SIZE, num_workers=0, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ccaf70bb0b6844",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T19:28:46.465520Z",
     "start_time": "2025-05-09T19:28:46.396237Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-09T20:32:15.137162Z",
     "iopub.status.busy": "2025-05-09T20:32:15.136465Z",
     "iopub.status.idle": "2025-05-09T20:32:15.285238Z",
     "shell.execute_reply": "2025-05-09T20:32:15.284652Z",
     "shell.execute_reply.started": "2025-05-09T20:32:15.137136Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = dataframe.label.nunique()\n",
    "metrics = {\n",
    "    \"acc\"      : MulticlassAccuracy(NUM_CLASSES, average=\"micro\").to(device),\n",
    "    \"f1_macro\" : MulticlassF1Score(NUM_CLASSES, average=\"macro\").to(device),\n",
    "    \"f1_weight\": MulticlassF1Score(NUM_CLASSES, average=\"weighted\").to(device),\n",
    "    \"top3\"     : MulticlassAccuracy(NUM_CLASSES, top_k=3).to(device),\n",
    "    \"cm\"       : MulticlassConfusionMatrix(NUM_CLASSES).to(device),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05da2105e3cd922",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T19:28:47.866591Z",
     "start_time": "2025-05-09T19:28:47.862955Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-09T20:32:17.099359Z",
     "iopub.status.busy": "2025-05-09T20:32:17.098796Z",
     "iopub.status.idle": "2025-05-09T20:32:17.103536Z",
     "shell.execute_reply": "2025-05-09T20:32:17.102853Z",
     "shell.execute_reply.started": "2025-05-09T20:32:17.099338Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9334d7d92978572",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T19:28:50.451264Z",
     "start_time": "2025-05-09T19:28:50.444303Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-09T20:32:18.939396Z",
     "iopub.status.busy": "2025-05-09T20:32:18.938721Z",
     "iopub.status.idle": "2025-05-09T20:32:18.947891Z",
     "shell.execute_reply": "2025-05-09T20:32:18.946905Z",
     "shell.execute_reply.started": "2025-05-09T20:32:18.939374Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(ml_model, loader, opt, sched):\n",
    "    ml_model.fit_data(); run_loss = 0.0\n",
    "    for xb, yb in tqdm(loader, leave=False):\n",
    "        xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "\n",
    "        out    = ml_model(xb)                     \n",
    "        logits = out[1] if isinstance(out, tuple) else out\n",
    "        loss   = F.cross_entropy(logits, yb)   \n",
    "\n",
    "        loss.backward(); opt.step(); sched.step()\n",
    "        run_loss += loss.item() * xb.size(0)\n",
    "    return run_loss / len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(ml_model, loader):\n",
    "    for m in metrics.values(): m.reset()\n",
    "    ml_model.eval(); run_loss = 0.0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        out    = ml_model(xb)                     \n",
    "        logits = out[1] if isinstance(out, tuple) else out\n",
    "        loss   = F.cross_entropy(logits, yb)\n",
    "\n",
    "        run_loss += loss.item() * xb.size(0)\n",
    "        for m in metrics.values(): m.update(logits, yb)\n",
    "    res = {\"loss\": run_loss / len(loader.dataset)}\n",
    "    res.update({k: m.compute().cpu().numpy() if k==\"cm\" else m.compute().item()\n",
    "                for k,m in metrics.items()})\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9656c351e672ff34",
   "metadata": {},
   "source": [
    "#### REsnet 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc992177fa16d59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T19:34:54.517751Z",
     "start_time": "2025-05-09T19:29:02.557344Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-09T20:32:20.807067Z",
     "iopub.status.busy": "2025-05-09T20:32:20.806533Z",
     "iopub.status.idle": "2025-05-09T20:41:37.824458Z",
     "shell.execute_reply": "2025-05-09T20:41:37.823702Z",
     "shell.execute_reply.started": "2025-05-09T20:32:20.807044Z"
    }
   },
   "outputs": [],
   "source": [
    "aux = dict(pooling=\"avg\", classes=NUM_CLASSES, dropout=0.0, activation=None)\n",
    "cnn = smp.Unet(encoder_name=\"resnet34\", encoder_weights=\"imagenet\",\n",
    "               classes=1, aux_params=aux).to(device)\n",
    "\n",
    "opt  = torch.optim.AdamW(cnn.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "sched= torch.optim.lr_scheduler.OneCycleLR(opt, max_lr=1e-3,\n",
    "        steps_per_epoch=len(train_dl), epochs=EPOCHS_BL)\n",
    "\n",
    "best_f1, best_wts = 0, None\n",
    "for epoch in range(EPOCHS_BL):\n",
    "    t_loss = train_one_epoch(cnn, train_dl, opt, sched)\n",
    "    val_stats = evaluate(cnn, val_dl)\n",
    "    print(f\"[{epoch+1:02d}] \"\n",
    "        f\"loss_tr={t_loss:.3f} | loss_val={val_stats['loss']:.3f} | \"\n",
    "        f\"Acc={val_stats['acc']:.3%} | \"\n",
    "        f\"F1(ma)={val_stats['f1_macro']:.3%} | F1(we)={val_stats['f1_weight']:.3%} | \"\n",
    "        f\"Top-3={val_stats['top3']:.3%}\")\n",
    "    if val_stats['f1_macro'] > best_f1:\n",
    "        best_f1, best_wts = val_stats['f1_macro'], cnn.state_dict()\n",
    "cnn.load_state_dict(best_wts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d6984a7585a225",
   "metadata": {},
   "source": [
    "#### ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b8bda43ab977d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T20:00:25.143083Z",
     "start_time": "2025-05-09T19:48:56.060966Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-09T20:51:33.852939Z",
     "iopub.status.busy": "2025-05-09T20:51:33.852320Z",
     "iopub.status.idle": "2025-05-09T21:01:12.993988Z",
     "shell.execute_reply": "2025-05-09T21:01:12.993315Z",
     "shell.execute_reply.started": "2025-05-09T20:51:33.852914Z"
    }
   },
   "outputs": [],
   "source": [
    "vit = smp.Unet(encoder_name=\"timm-efficientnet-b0\",\n",
    "               encoder_weights=\"imagenet\", classes=1, aux_params=aux).to(device)\n",
    "\n",
    "opt  = torch.optim.AdamW(vit.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "sched= torch.optim.lr_scheduler.OneCycleLR(opt, max_lr=1e-3,\n",
    "        steps_per_epoch=len(train_dl), epochs=EPOCHS_BL)\n",
    "\n",
    "best_f1, best_wts = 0, None\n",
    "for epoch in range(EPOCHS_BL):\n",
    "    tl = train_one_epoch(vit, train_dl, opt, sched)\n",
    "    vs = evaluate(vit, val_dl)\n",
    "    print(f\"[{epoch+1:02d}] \"\n",
    "        f\"loss_tr={tl:.3f} | loss_val={vs['loss']:.3f} | \"\n",
    "        f\"Acc={vs['acc']:.3%} | \"\n",
    "        f\"F1(ma)={vs['f1_macro']:.3%} | F1(we)={vs['f1_weight']:.3%} | \"\n",
    "        f\"Top-3={vs['top3']:.3%}\")\n",
    "    if vs['f1_macro'] > best_f1:\n",
    "        best_f1, best_wts = vs['f1_macro'], vit.state_dict()\n",
    "vit.load_state_dict(best_wts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458ea0b4-2b79-4627-b179-22b096e39155",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T21:26:31.080081Z",
     "iopub.status.busy": "2025-05-09T21:26:31.079810Z",
     "iopub.status.idle": "2025-05-09T21:26:52.423644Z",
     "shell.execute_reply": "2025-05-09T21:26:52.422777Z",
     "shell.execute_reply.started": "2025-05-09T21:26:31.080060Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "class_names = sorted(dataframe.label.unique())          \n",
    "\n",
    "\n",
    "models = [\n",
    "    (\"ResNet-34 UNet\", cnn),   \n",
    "    (\"ViT-b0 UNet\",   vit),    \n",
    "]\n",
    "\n",
    "for title, mdl in models:\n",
    "    mdl.eval()                               \n",
    "    vs = evaluate(mdl, val_dl)               \n",
    "    cm = vs[\"cm\"]                            \n",
    "\n",
    "    \n",
    "    print(f\"\\n{title} — confusion matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True, fmt=\"d\",                 \n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "        linewidths=.5, cbar=False,\n",
    "    )\n",
    "    plt.title(f\"{title} — validation set\")\n",
    "    plt.xlabel(\"Предсказанный класс\")\n",
    "    plt.ylabel(\"Истинный класс\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4773b4fd-aebd-47cd-ad26-e7ccbe98a9aa",
   "metadata": {},
   "source": [
    "# Улучшение бейзлайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cedac3-7b91-408c-8e29-afde95423719",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T21:49:00.363763Z",
     "iopub.status.busy": "2025-05-09T21:49:00.363410Z",
     "iopub.status.idle": "2025-05-09T21:49:00.368929Z",
     "shell.execute_reply": "2025-05-09T21:49:00.368190Z",
     "shell.execute_reply.started": "2025-05-09T21:49:00.363725Z"
    }
   },
   "outputs": [],
   "source": [
    "import albumentations as A, importlib\n",
    "print(\"Albumentations version →\", A.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e7d0f3-0f81-4bde-ab6c-f0069baf960a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T21:57:45.217422Z",
     "iopub.status.busy": "2025-05-09T21:57:45.217155Z",
     "iopub.status.idle": "2025-05-09T21:57:45.228500Z",
     "shell.execute_reply": "2025-05-09T21:57:45.227942Z",
     "shell.execute_reply.started": "2025-05-09T21:57:45.217403Z"
    }
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "IMG_SIZE = 224          \n",
    "\n",
    "\n",
    "train_tfms = A.Compose(\n",
    "    [\n",
    "\n",
    "        A.RandomResizedCrop(\n",
    "            size=(IMG_SIZE, IMG_SIZE),     \n",
    "            scale=(0.7, 1.0),              \n",
    "            ratio=(0.75, 1.333),          \n",
    "            p=1.0,\n",
    "        ),\n",
    "\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.2),\n",
    "        A.RandomRotate90(p=0.3),\n",
    "\n",
    "        A.ColorJitter(\n",
    "            brightness=0.2, contrast=0.2,\n",
    "            saturation=0.2, hue=0.1, p=0.5\n",
    "        ),\n",
    "        A.CLAHE(p=0.2),\n",
    "        A.RandomBrightnessContrast(p=0.3),\n",
    "\n",
    "        \n",
    "        A.CoarseDropout(\n",
    "            num_holes_range=(1, 1),           \n",
    "            hole_height_range=(0.25, 0.25),    \n",
    "            hole_width_range=(0.25, 0.25),     \n",
    "            p=0.3,\n",
    "        ),\n",
    "\n",
    "        A.Normalize(\n",
    "            mean=(0.485, 0.456, 0.406),\n",
    "            std=(0.229, 0.224, 0.225),\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    "    strict=True,         \n",
    ")\n",
    "\n",
    "valid_tfms = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=IMG_SIZE, width=IMG_SIZE),\n",
    "        A.Normalize(\n",
    "            mean=(0.485, 0.456, 0.406),\n",
    "            std=(0.229, 0.224, 0.225),\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    "    strict=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21cfb0d-c7f3-47b6-982b-033ad66219e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T22:01:02.973573Z",
     "iopub.status.busy": "2025-05-09T22:01:02.973311Z",
     "iopub.status.idle": "2025-05-09T22:01:02.981226Z",
     "shell.execute_reply": "2025-05-09T22:01:02.980410Z",
     "shell.execute_reply.started": "2025-05-09T22:01:02.973553Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "opt_cnn = torch.optim.AdamW(cnn.parameters(), lr=3e-4, weight_decay=1e-2)\n",
    "opt_vit = torch.optim.AdamW(vit.parameters(), lr=5e-5, weight_decay=1e-2)\n",
    "\n",
    "sch_cnn = CosineAnnealingWarmRestarts(opt_cnn, T_0=4, T_mult=2)\n",
    "sch_vit = CosineAnnealingWarmRestarts(opt_vit, T_0=4, T_mult=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e32abd-6d8f-4ae7-a812-3485208e32ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T22:01:08.493511Z",
     "iopub.status.busy": "2025-05-09T22:01:08.493238Z",
     "iopub.status.idle": "2025-05-09T22:01:08.499737Z",
     "shell.execute_reply": "2025-05-09T22:01:08.498869Z",
     "shell.execute_reply.started": "2025-05-09T22:01:08.493491Z"
    }
   },
   "outputs": [],
   "source": [
    "def toggle_backbone(ml_model, freeze: bool):\n",
    "    for n, p in ml_model.named_parameters():\n",
    "        p.requires_grad = not freeze or n.startswith((\"fc\", \"head\", \"classifier\"))\n",
    "\n",
    "toggle_backbone(cnn, True)\n",
    "toggle_backbone(vit, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed20f35-7ac2-4311-b2e3-e2d7dfdd9fc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T22:01:17.918502Z",
     "iopub.status.busy": "2025-05-09T22:01:17.917783Z",
     "iopub.status.idle": "2025-05-09T22:01:17.923887Z",
     "shell.execute_reply": "2025-05-09T22:01:17.923113Z",
     "shell.execute_reply.started": "2025-05-09T22:01:17.918476Z"
    }
   },
   "outputs": [],
   "source": [
    "toggle_backbone(cnn, False)\n",
    "toggle_backbone(vit, False)\n",
    "for g in opt_cnn.param_groups: g[\"lr\"] = 1e-4\n",
    "for g in opt_vit.param_groups: g[\"lr\"] = 2e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba42352e-2b69-44f0-9bea-bacec75294c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T22:20:09.001877Z",
     "iopub.status.busy": "2025-05-09T22:20:09.001319Z",
     "iopub.status.idle": "2025-05-09T22:57:07.807939Z",
     "shell.execute_reply": "2025-05-09T22:57:07.807052Z",
     "shell.execute_reply.started": "2025-05-09T22:20:09.001854Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "\n",
    "toggle_backbone(cnn, False)\n",
    "toggle_backbone(vit, False)\n",
    "\n",
    "\n",
    "\n",
    "def train_one_epoch_imp(ml_model, loader, opt, sched):\n",
    "    ml_model.fit_data()\n",
    "    run_loss = 0.0\n",
    "    for xb, yb in tqdm(loader, leave=False):\n",
    "        xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        out = ml_model(xb)\n",
    "        logits = out[1] if isinstance(out, tuple) else out\n",
    "        loss = criterion(logits, yb)\n",
    "        \n",
    "        if not loss.requires_grad:\n",
    "            raise RuntimeError(\n",
    "                \"Loss не требует градиента. Проверьте, что параметры модели имеют requires_grad=True\"\n",
    "            )\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        sched.step()\n",
    "        run_loss += loss.item() * xb.size(0)\n",
    "    return run_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "best_f1_imp_cnn, best_wts_imp_cnn = 0, None\n",
    "for epoch in range(EPOCHS_IMP):\n",
    "    t_loss = train_one_epoch_imp(cnn, train_dl, opt_cnn, sch_cnn)\n",
    "    val_stats = evaluate(cnn, val_dl)\n",
    "    print(f\"[Imp CNN {epoch+1:02d}] \"\n",
    "          f\"loss_tr={t_loss:.3f} | loss_val={val_stats['loss']:.3f} | \"\n",
    "          f\"Acc={val_stats['acc']:.3%} | F1(ma)={val_stats['f1_macro']:.3%}\")\n",
    "    if val_stats['f1_macro'] > best_f1_imp_cnn:\n",
    "        best_f1_imp_cnn, best_wts_imp_cnn = val_stats['f1_macro'], cnn.state_dict()\n",
    "cnn.load_state_dict(best_wts_imp_cnn)\n",
    "\n",
    "\n",
    "best_f1_imp_vit, best_wts_imp_vit = 0, None\n",
    "for epoch in range(EPOCHS_IMP):\n",
    "    t_loss = train_one_epoch_imp(vit, train_dl, opt_vit, sch_vit)\n",
    "    val_stats = evaluate(vit, val_dl)\n",
    "    print(f\"[Imp ViT {epoch+1:02d}] \"\n",
    "          f\"loss_tr={t_loss:.3f} | loss_val={val_stats['loss']:.3f} | \"\n",
    "          f\"Acc={val_stats['acc']:.3%} | F1(ma)={val_stats['f1_macro']:.3%}\")\n",
    "    if val_stats['f1_macro'] > best_f1_imp_vit:\n",
    "        best_f1_imp_vit, best_wts_imp_vit = val_stats['f1_macro'], vit.state_dict()\n",
    "vit.load_state_dict(best_wts_imp_vit)\n",
    "\n",
    "\n",
    "for title, mdl in [(\"Improved CNN\", cnn), (\"Improved ViT\", vit)]:\n",
    "    mdl.eval()\n",
    "    stats = evaluate(mdl, val_dl)\n",
    "    print(f\"{title}: Acc={stats['acc']:.3%}, F1(ma)={stats['f1_macro']:.3%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa34001-0930-476f-a948-2c341deae2a4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde5e5bc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-10T11:48:49.241648Z",
     "iopub.status.busy": "2025-05-10T11:48:49.240838Z",
     "iopub.status.idle": "2025-05-10T11:48:52.684131Z",
     "shell.execute_reply": "2025-05-10T11:48:52.683122Z",
     "shell.execute_reply.started": "2025-05-10T11:48:49.241622Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install -q ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e07f273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:01:06.160275Z",
     "iopub.status.busy": "2025-05-10T13:01:06.160002Z",
     "iopub.status.idle": "2025-05-10T13:01:06.167087Z",
     "shell.execute_reply": "2025-05-10T13:01:06.166577Z",
     "shell.execute_reply.started": "2025-05-10T13:01:06.160254Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, random, pathlib, zipfile, shutil\n",
    "import pandas as pd, numpy as np, torch\n",
    "from torch.utils.dataset import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy, MulticlassF1Score, MulticlassConfusionMatrix\n",
    ")\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "IMG_SIZE    = 224\n",
    "BATCH_SIZE  = 32\n",
    "NUM_WORKERS = 4\n",
    "EPOCHS_BL   = 10\n",
    "EPOCHS_IMP  = 20\n",
    "device      = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1992da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:01:15.663890Z",
     "iopub.status.busy": "2025-05-10T13:01:15.663631Z",
     "iopub.status.idle": "2025-05-10T13:01:15.702121Z",
     "shell.execute_reply": "2025-05-10T13:01:15.701519Z",
     "shell.execute_reply.started": "2025-05-10T13:01:15.663873Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = pathlib.Path(\"/kaggle/input/realwaste/realwaste-main/RealWaste\")\n",
    "all_images = []\n",
    "for class_idx, class_name in enumerate(sorted(p.name for p in DATA_DIR.iterdir())):\n",
    "    for img_path in (DATA_DIR / class_name).glob(\"*\"):\n",
    "        all_images.append((str(img_path), class_idx, class_name))\n",
    "dataframe = pd.DataFrame(all_images, columns=[\"path\",\"label\",\"class\"])\n",
    "print(dataframe['class'].value_counts())\n",
    "NUM_CLASSES = dataframe.label.nunique()\n",
    "class_names = sorted(dataframe[\"class\"].unique())\n",
    "print(f\"Found {NUM_CLASSES} classes: {class_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ab305a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:01:30.711980Z",
     "iopub.status.busy": "2025-05-10T13:01:30.711380Z",
     "iopub.status.idle": "2025-05-10T13:01:30.723373Z",
     "shell.execute_reply": "2025-05-10T13:01:30.722432Z",
     "shell.execute_reply.started": "2025-05-10T13:01:30.711955Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, tmp_df = train_test_split(\n",
    "    dataframe, test_size=0.30, random_state=SEED, stratify=dataframe[\"label\"]\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    tmp_df, test_size=0.50, random_state=SEED, stratify=tmp_df[\"label\"]\n",
    ")\n",
    "print(f\"fit_data: {len(train_df)}, val: {len(val_df)}, eval_data: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742fb3ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:01:38.578669Z",
     "iopub.status.busy": "2025-05-10T13:01:38.578334Z",
     "iopub.status.idle": "2025-05-10T13:01:38.588682Z",
     "shell.execute_reply": "2025-05-10T13:01:38.587897Z",
     "shell.execute_reply.started": "2025-05-10T13:01:38.578643Z"
    }
   },
   "outputs": [],
   "source": [
    "train_tfms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(.8,1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE+32),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "class WasteDataset(Dataset):\n",
    "    def __init__(self, dataframe, tfm):\n",
    "        self.dataframe  = dataframe.reset_index(drop=True)\n",
    "        self.tfm = tfm\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    def __getitem__(self, i):\n",
    "        img = Image.open(self.dataframe.loc[i,\"path\"]).convert(\"RGB\")\n",
    "        x_val = self.tfm(img)\n",
    "        y_val = self.dataframe.loc[i,\"label\"]\n",
    "        return x_val, y_val\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    WasteDataset(train_df, train_tfms),\n",
    "    batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True\n",
    ")\n",
    "val_dl = DataLoader(\n",
    "    WasteDataset(val_df, val_tfms),\n",
    "    batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True\n",
    ")\n",
    "test_dl = DataLoader(\n",
    "    WasteDataset(test_df, val_tfms),\n",
    "    batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867c8c9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T11:49:01.420245Z",
     "iopub.status.busy": "2025-05-10T11:49:01.419590Z",
     "iopub.status.idle": "2025-05-10T11:49:01.431204Z",
     "shell.execute_reply": "2025-05-10T11:49:01.430364Z",
     "shell.execute_reply.started": "2025-05-10T11:49:01.420215Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"acc\"       : MulticlassAccuracy(NUM_CLASSES, average=\"micro\").to(device),\n",
    "    \"f1_macro\"  : MulticlassF1Score(NUM_CLASSES, average=\"macro\").to(device),\n",
    "    \"f1_weight\" : MulticlassF1Score(NUM_CLASSES, average=\"weighted\").to(device),\n",
    "    \"top3\"      : MulticlassAccuracy(NUM_CLASSES, top_k=3).to(device),\n",
    "    \"cm\"        : MulticlassConfusionMatrix(NUM_CLASSES).to(device),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfcee9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:04:31.610393Z",
     "iopub.status.busy": "2025-05-10T13:04:31.610063Z",
     "iopub.status.idle": "2025-05-10T13:04:52.490235Z",
     "shell.execute_reply": "2025-05-10T13:04:52.489604Z",
     "shell.execute_reply.started": "2025-05-10T13:04:31.610370Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_DIR = Path(\"realwaste_split\")\n",
    "if OUT_DIR.exists():\n",
    "    shutil.rmtree(OUT_DIR)\n",
    "\n",
    "for split, df_split in [(\"fit_data\", train_df), (\"val\", val_df), (\"eval_data\", test_df)]:\n",
    "    for _, row in df_split.iterrows():\n",
    "        cls = row[\"class\"]\n",
    "        src = Path(row[\"path\"])\n",
    "        dst_dir = OUT_DIR / split / cls\n",
    "        dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy(src, dst_dir / src.name)\n",
    "\n",
    "print(\"✓ Папки realwaste_split/fit_data, val, eval_data созданы\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc209c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:10:09.290172Z",
     "iopub.status.busy": "2025-05-10T13:10:09.289868Z",
     "iopub.status.idle": "2025-05-10T13:10:09.296030Z",
     "shell.execute_reply": "2025-05-10T13:10:09.295411Z",
     "shell.execute_reply.started": "2025-05-10T13:10:09.290149Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path(\"realwaste_split\").resolve()\n",
    "\n",
    "yaml_content = f\"\"\"\n",
    "fit_data: {ROOT}/fit_data\n",
    "val:   {ROOT}/val\n",
    "eval_data:  {ROOT}/eval_data\n",
    "\n",
    "nc: {NUM_CLASSES}\n",
    "names: {class_names}\n",
    "\"\"\"\n",
    "with open(\"realwaste.yaml\", \"w\") as f:\n",
    "    f.write(yaml_content.strip())\n",
    "print(open(\"realwaste.yaml\").read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c048ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:12:19.665524Z",
     "iopub.status.busy": "2025-05-10T13:12:19.665271Z",
     "iopub.status.idle": "2025-05-10T13:12:20.685757Z",
     "shell.execute_reply": "2025-05-10T13:12:20.685115Z",
     "shell.execute_reply.started": "2025-05-10T13:12:19.665507Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "\n",
    "src = \"realwaste_split\"\n",
    "dst = \"/kaggle/working/datasets/realwaste_split\"\n",
    "\n",
    "if os.path.exists(dst):\n",
    "    shutil.rmtree(dst)\n",
    "\n",
    "shutil.copytree(src, dst)\n",
    "print(f\"✓ Скопировали `{src}` → `{dst}`\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8941306f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:33:14.690828Z",
     "iopub.status.busy": "2025-05-10T13:33:14.690565Z",
     "iopub.status.idle": "2025-05-10T13:33:14.696412Z",
     "shell.execute_reply": "2025-05-10T13:33:14.695735Z",
     "shell.execute_reply.started": "2025-05-10T13:33:14.690811Z"
    }
   },
   "outputs": [],
   "source": [
    "yaml = f\"\"\"\n",
    "path: realwaste_split\n",
    "\n",
    "fit_data: fit_data\n",
    "val:   val\n",
    "eval_data:  eval_data\n",
    "\n",
    "nc: {NUM_CLASSES}\n",
    "names: {class_names}\n",
    "\"\"\".strip()\n",
    "\n",
    "with open(\"realwaste.yaml\",\"w\") as f:\n",
    "    f.write(yaml)\n",
    "\n",
    "print(open(\"realwaste.yaml\").read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90d08bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:37:34.304913Z",
     "iopub.status.busy": "2025-05-10T13:37:34.304601Z",
     "iopub.status.idle": "2025-05-10T13:40:40.610666Z",
     "shell.execute_reply": "2025-05-10T13:40:40.609714Z",
     "shell.execute_reply.started": "2025-05-10T13:37:34.304891Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT = str(Path(\"realwaste_split\").resolve())\n",
    "model_clf = YOLO('yolov8n-cls.pt', task='classify')\n",
    "model_clf.fit_data(\n",
    "    dataset=ROOT,       \n",
    "    epochs=EPOCHS_BL,\n",
    "    imgsz=IMG_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    workers=NUM_WORKERS,\n",
    "    device=device.type,\n",
    "    name='baseline_yolov8n-cls'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69acd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:48:06.374360Z",
     "iopub.status.busy": "2025-05-10T13:48:06.374015Z",
     "iopub.status.idle": "2025-05-10T13:48:10.085999Z",
     "shell.execute_reply": "2025-05-10T13:48:10.085019Z",
     "shell.execute_reply.started": "2025-05-10T13:48:06.374328Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy, MulticlassF1Score, MulticlassConfusionMatrix\n",
    ")\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    \"acc\"       : MulticlassAccuracy(NUM_CLASSES, average=\"micro\").to(device),\n",
    "    \"f1_macro\"  : MulticlassF1Score(NUM_CLASSES, average=\"macro\").to(device),\n",
    "    \"f1_weight\" : MulticlassF1Score(NUM_CLASSES, average=\"weighted\").to(device),\n",
    "    \"top3\"      : MulticlassAccuracy(NUM_CLASSES, top_k=3).to(device),\n",
    "    \"cm\"        : MulticlassConfusionMatrix(NUM_CLASSES).to(device),\n",
    "}\n",
    "\n",
    "ml_model = model_clf.ml_model\n",
    "ml_model.to(device).eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in tqdm(test_dl, desc=\"Inferencing on eval_data\"):\n",
    "        xb = xb.to(device); yb = yb.to(device)\n",
    "        out = ml_model(xb)\n",
    "        logits = out[1] if isinstance(out, (tuple, list)) else out\n",
    "        preds = logits.argmax(dim=1)\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(yb)\n",
    "\n",
    "y_pred = torch.cat(all_preds)\n",
    "y_true = torch.cat(all_labels)\n",
    "\n",
    "acc       = metrics[\"acc\"](y_pred, y_true)\n",
    "f1_macro  = metrics[\"f1_macro\"](y_pred, y_true)\n",
    "f1_weight = metrics[\"f1_weight\"](y_pred, y_true)\n",
    "cm        = metrics[\"cm\"](y_pred, y_true)\n",
    "\n",
    "print(f\"Accuracy (micro)     : {acc:.4f}\")\n",
    "print(f\"F1-score (macro)     : {f1_macro:.4f}\")\n",
    "print(f\"F1-score (weighted)  : {f1_weight:.4f}\")\n",
    "\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "sns.heatmap(cm.cpu().numpy(), annot=True, fmt=\"d\",\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73678372",
   "metadata": {},
   "source": [
    "Чето вообще все фигово выглядит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd59815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:56:16.518984Z",
     "iopub.status.busy": "2025-05-10T13:56:16.518532Z",
     "iopub.status.idle": "2025-05-10T13:56:16.543096Z",
     "shell.execute_reply": "2025-05-10T13:56:16.542216Z",
     "shell.execute_reply.started": "2025-05-10T13:56:16.518949Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.dataset import WeightedRandomSampler\n",
    "\n",
    "counts = train_df['label'].value_counts().sort_index()\n",
    "print(\"Train class counts:\\n\", counts)\n",
    "\n",
    "class_weights = 1.0 / counts.values\n",
    "sample_weights = train_df['label'].map(lambda x_val: class_weights[x_val]).values\n",
    "sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    WasteDataset(train_df, train_tfms),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=sampler,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458e8c04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:59:34.546915Z",
     "iopub.status.busy": "2025-05-10T13:59:34.546616Z",
     "iopub.status.idle": "2025-05-10T13:59:34.552500Z",
     "shell.execute_reply": "2025-05-10T13:59:34.551703Z",
     "shell.execute_reply.started": "2025-05-10T13:59:34.546894Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = dataframe.label.nunique()\n",
    "class_names = sorted(dataframe['class'].unique())\n",
    "ROOT = str(Path(\"realwaste_split\").resolve())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd1f65d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:59:47.707333Z",
     "iopub.status.busy": "2025-05-10T13:59:47.707011Z",
     "iopub.status.idle": "2025-05-10T13:59:47.715426Z",
     "shell.execute_reply": "2025-05-10T13:59:47.714602Z",
     "shell.execute_reply.started": "2025-05-10T13:59:47.707312Z"
    }
   },
   "outputs": [],
   "source": [
    "counts = train_df['label'].value_counts().sort_index()\n",
    "class_weights = 1.0 / counts.values\n",
    "sample_weights = train_df['label'].map(lambda x_val: class_weights[x_val]).values\n",
    "\n",
    "sampler = WeightedRandomSampler(sample_weights,\n",
    "                                num_samples=len(sample_weights),\n",
    "                                replacement=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700b907e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:59:58.796136Z",
     "iopub.status.busy": "2025-05-10T13:59:58.795526Z",
     "iopub.status.idle": "2025-05-10T13:59:58.802153Z",
     "shell.execute_reply": "2025-05-10T13:59:58.801305Z",
     "shell.execute_reply.started": "2025-05-10T13:59:58.796112Z"
    }
   },
   "outputs": [],
   "source": [
    "train_tfms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.7,1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.3),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, \n",
    "                           saturation=0.2, hue=0.1),\n",
    "    transforms.RandomErasing(p=0.4, scale=(0.02,0.2)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std =[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE+32),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std =[0.229,0.224,0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3266cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T14:00:08.769089Z",
     "iopub.status.busy": "2025-05-10T14:00:08.768809Z",
     "iopub.status.idle": "2025-05-10T14:00:08.777256Z",
     "shell.execute_reply": "2025-05-10T14:00:08.776586Z",
     "shell.execute_reply.started": "2025-05-10T14:00:08.769069Z"
    }
   },
   "outputs": [],
   "source": [
    "class WasteDataset(Dataset):\n",
    "    def __init__(self, dataframe, tfm):\n",
    "        self.dataframe  = dataframe.reset_index(drop=True)\n",
    "        self.tfm = tfm\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    def __getitem__(self, i):\n",
    "        img = Image.open(self.dataframe.loc[i,'path']).convert('RGB')\n",
    "        return self.tfm(img), self.dataframe.loc[i,'label']\n",
    "\n",
    "train_ds = WasteDataset(train_df, train_tfms)\n",
    "val_ds   = WasteDataset(val_df,   val_tfms)\n",
    "test_ds  = WasteDataset(test_df,  val_tfms)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                      sampler=sampler,\n",
    "                      num_workers=NUM_WORKERS,\n",
    "                      pin_memory=True)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=BATCH_SIZE,\n",
    "                      shuffle=False,\n",
    "                      num_workers=NUM_WORKERS,\n",
    "                      pin_memory=True)\n",
    "test_dl  = DataLoader(test_ds,  batch_size=BATCH_SIZE,\n",
    "                      shuffle=False,\n",
    "                      num_workers=NUM_WORKERS,\n",
    "                      pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa3cd9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T14:00:20.746272Z",
     "iopub.status.busy": "2025-05-10T14:00:20.745993Z",
     "iopub.status.idle": "2025-05-10T14:07:48.772815Z",
     "shell.execute_reply": "2025-05-10T14:07:48.772052Z",
     "shell.execute_reply.started": "2025-05-10T14:00:20.746251Z"
    }
   },
   "outputs": [],
   "source": [
    "model_imp = YOLO('yolov8m-cls.pt', task='classify')\n",
    "model_imp.fit_data(\n",
    "    dataset=ROOT,\n",
    "    epochs=EPOCHS_IMP,\n",
    "    imgsz=IMG_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    workers=NUM_WORKERS,\n",
    "    device=device.type,\n",
    "    name='improved_yolov8m-cls',\n",
    "    lr0=0.01,\n",
    "    lrf=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15344c02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T14:11:35.875321Z",
     "iopub.status.busy": "2025-05-10T14:11:35.875028Z",
     "iopub.status.idle": "2025-05-10T14:11:59.768727Z",
     "shell.execute_reply": "2025-05-10T14:11:59.767869Z",
     "shell.execute_reply.started": "2025-05-10T14:11:35.875300Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy, MulticlassF1Score, MulticlassConfusionMatrix\n",
    ")\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "\n",
    "\n",
    "k = min(3, NUM_CLASSES)\n",
    "metrics = {\n",
    "    \"acc\"       : MulticlassAccuracy(NUM_CLASSES, average=\"micro\").to(device),\n",
    "    \"f1_macro\"  : MulticlassF1Score(NUM_CLASSES, average=\"macro\").to(device),\n",
    "    \"f1_weight\" : MulticlassF1Score(NUM_CLASSES, average=\"weighted\").to(device),\n",
    "    \"cm\"        : MulticlassConfusionMatrix(NUM_CLASSES).to(device),\n",
    "}\n",
    "\n",
    "\n",
    "mdl = model_imp.ml_model.to(device).eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in tqdm(test_dl, desc=\"Inferencing\"):\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        out = mdl(xb)\n",
    "        logits = out[1] if isinstance(out,(tuple,list)) else out\n",
    "        preds = logits.argmax(dim=1)\n",
    "        all_preds.append(preds); all_labels.append(yb)\n",
    "\n",
    "y_pred = torch.cat(all_preds)\n",
    "y_true = torch.cat(all_labels)\n",
    "\n",
    "\n",
    "acc       = metrics[\"acc\"](y_pred, y_true)\n",
    "f1m       = metrics[\"f1_macro\"](y_pred, y_true)\n",
    "f1w       = metrics[\"f1_weight\"](y_pred, y_true)\n",
    "cm        = metrics[\"cm\"](y_pred, y_true)\n",
    "\n",
    "print(f\"acc={acc:.4f}, f1_macro={f1m:.4f}, f1_weight={f1w:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm.cpu().numpy(), annot=True, fmt=\"d\",\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3358fbea",
   "metadata": {},
   "source": [
    "Стало лучше, но все равно плохо. Из матриц видно что метал плохо определяется и со всем путается."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22501f90",
   "metadata": {},
   "source": [
    "Перейдем к трансформерам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897c8765",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T14:15:54.348968Z",
     "iopub.status.busy": "2025-05-10T14:15:54.348343Z",
     "iopub.status.idle": "2025-05-10T14:15:54.365497Z",
     "shell.execute_reply": "2025-05-10T14:15:54.364572Z",
     "shell.execute_reply.started": "2025-05-10T14:15:54.348940Z"
    }
   },
   "outputs": [],
   "source": [
    "counts = train_df['label'].value_counts().sort_index()\n",
    "class_weights   = 1.0 / counts.values\n",
    "sample_weights  = train_df['label'].map(lambda x_val: class_weights[x_val]).values\n",
    "sampler         = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.7,1.0)),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE+32),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "class WasteDataset(Dataset):\n",
    "    def __init__(self, dataframe, tfm):\n",
    "        self.dataframe  = dataframe.reset_index(drop=True); self.tfm = tfm\n",
    "    def __len__(self):    return len(self.dataframe)\n",
    "    def __getitem__(self, i):\n",
    "        img = Image.open(self.dataframe.loc[i,'path']).convert('RGB')\n",
    "        return self.tfm(img), self.dataframe.loc[i,'label']\n",
    "\n",
    "train_dl = DataLoader(WasteDataset(train_df, train_tfms),\n",
    "                      batch_size=BATCH_SIZE, sampler=sampler,\n",
    "                      num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_dl   = DataLoader(WasteDataset(val_df,   val_tfms),\n",
    "                      batch_size=BATCH_SIZE, shuffle=False,\n",
    "                      num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_dl  = DataLoader(WasteDataset(test_df,  val_tfms),\n",
    "                      batch_size=BATCH_SIZE, shuffle=False,\n",
    "                      num_workers=NUM_WORKERS, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe8f7a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T14:16:13.553574Z",
     "iopub.status.busy": "2025-05-10T14:16:13.552843Z",
     "iopub.status.idle": "2025-05-10T14:19:25.828878Z",
     "shell.execute_reply": "2025-05-10T14:19:25.827866Z",
     "shell.execute_reply.started": "2025-05-10T14:16:13.553521Z"
    }
   },
   "outputs": [],
   "source": [
    "model_bl = YOLO('yolo11n-cls.pt', task='classify')\n",
    "model_bl.fit_data(\n",
    "    dataset=ROOT,         \n",
    "    epochs=EPOCHS_BL,\n",
    "    imgsz=IMG_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    workers=NUM_WORKERS,\n",
    "    device=device.type,\n",
    "    name='baseline_yolo11n-cls',\n",
    "    lr0=0.01,          \n",
    "    lrf=0.1            \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b146c025",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T14:20:05.540640Z",
     "iopub.status.busy": "2025-05-10T14:20:05.540295Z",
     "iopub.status.idle": "2025-05-10T14:26:36.521600Z",
     "shell.execute_reply": "2025-05-10T14:26:36.520532Z",
     "shell.execute_reply.started": "2025-05-10T14:20:05.540611Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model_imp = YOLO('yolo11m-cls.pt', task='classify')\n",
    "model_imp.fit_data(\n",
    "    dataset=ROOT,\n",
    "    epochs=EPOCHS_IMP,\n",
    "    imgsz=IMG_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    workers=NUM_WORKERS,\n",
    "    device=device.type,\n",
    "    name='improved_yolo11m-cls',\n",
    "    lr0=0.01,\n",
    "    lrf=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c31e7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T14:27:19.891755Z",
     "iopub.status.busy": "2025-05-10T14:27:19.891417Z",
     "iopub.status.idle": "2025-05-10T14:27:47.590476Z",
     "shell.execute_reply": "2025-05-10T14:27:47.589387Z",
     "shell.execute_reply.started": "2025-05-10T14:27:19.891724Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "k = min(3, NUM_CLASSES)\n",
    "metrics = {\n",
    "    \"acc\"      : MulticlassAccuracy(NUM_CLASSES, average=\"micro\").to(device),\n",
    "    \"f1_macro\" : MulticlassF1Score(NUM_CLASSES, average=\"macro\").to(device),\n",
    "    \"f1_weight\": MulticlassF1Score(NUM_CLASSES, average=\"weighted\").to(device),\n",
    "    \"cm\"       : MulticlassConfusionMatrix(NUM_CLASSES).to(device),\n",
    "}\n",
    "\n",
    "def eval_model(yolo_model, dl):\n",
    "    mdl = yolo_model.ml_model.to(device).eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in tqdm(dl, desc=\"Inferencing\"):\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            out = mdl(xb)\n",
    "            logits = out[1] if isinstance(out,(tuple,list)) else out\n",
    "            preds = logits.argmax(dim=1)\n",
    "            all_preds.append(preds); all_labels.append(yb)\n",
    "    y_pred = torch.cat(all_preds); y_true = torch.cat(all_labels)\n",
    "    return {\n",
    "        'acc':      metrics[\"acc\"](y_pred, y_true).item(),\n",
    "        'f1_macro': metrics[\"f1_macro\"](y_pred, y_true).item(),\n",
    "        'f1_weight':metrics[\"f1_weight\"](y_pred, y_true).item(),\n",
    "        'cm':       metrics[\"cm\"](y_pred, y_true).cpu().numpy()\n",
    "    }\n",
    "\n",
    "\n",
    "res_bl = eval_model(model_bl, test_dl)\n",
    "\n",
    "res_imp = eval_model(model_imp, test_dl)\n",
    "\n",
    "\n",
    "print(\"Baseline YOLO11n-cls:\", {k:round(v,4) for k,v in res_bl.items() if k!='cm'})\n",
    "print(\"Improved YOLO11m-cls:\",{k:round(v,4) for k,v in res_imp.items() if k!='cm'})\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(res_imp['cm'], annot=True, fmt=\"d\",\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix (improved)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "Установка зависимостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea874ccc33981",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:28:05.169715Z",
     "start_time": "2025-05-09T11:27:21.986905Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install torch torchvision torchmetrics kaggle scikit-learn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc121e30a2defb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:32:07.866206Z",
     "start_time": "2025-05-09T14:32:06.380590Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import zipfile, os, shutil, random, pathlib\n",
    "\n",
    "\n",
    "\n",
    "DATA_DIR = pathlib.Path(\"./archive/realwaste-main/RealWaste\")\n",
    "all_images = []\n",
    "for class_idx, class_name in enumerate(sorted(p.name for p in DATA_DIR.iterdir())):\n",
    "    for img_path in (DATA_DIR / class_name).glob(\"*\"):\n",
    "        all_images.append((img_path, class_idx, class_name))\n",
    "\n",
    "dataframe = pd.DataFrame(all_images, columns=[\"path\", \"label\", \"class\"])\n",
    "train_df, tmp_df = train_test_split(\n",
    "    dataframe, test_size=0.30, random_state=42, stratify=dataframe[\"label\"]\n",
    ")\n",
    "val_df, test_df  = train_test_split(\n",
    "    tmp_df, test_size=0.50, random_state=42, stratify=tmp_df[\"label\"]\n",
    ")\n",
    "print(f\"fit_data {len(train_df)}, val {len(val_df)}, eval_data {len(test_df)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b258789e294ded5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:32:17.608911Z",
     "start_time": "2025-05-09T14:32:13.238012Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "IMG_SIZE = 224\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std=[0.229,0.224,0.225]),\n",
    "])\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE + 32),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "class DFImageDataset(torch.utils.dataset.Dataset):\n",
    "    def __init__(self, dataframe, tfms):\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.tfms = tfms\n",
    "    def __len__(self): return len(self.dataframe)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        img = Image.open(row.path).convert(\"RGB\")\n",
    "        return self.tfms(img), row.label\n",
    "\n",
    "train_ds = DFImageDataset(train_df, train_tfms)\n",
    "val_ds   = DFImageDataset(val_df,   val_tfms)\n",
    "test_ds  = DFImageDataset(test_df,  val_tfms)\n",
    "\n",
    "batch_size = 32\n",
    "train_dl = torch.utils.dataset.DataLoader(train_ds, batch_size=batch_size,\n",
    "                                       shuffle=True,  num_workers=0, pin_memory=True, persistent_workers = False)\n",
    "val_dl   = torch.utils.dataset.DataLoader(val_ds,   batch_size=batch_size,\n",
    "                                       shuffle=False, num_workers=0, pin_memory=True, persistent_workers = False)\n",
    "test_dl  = torch.utils.dataset.DataLoader(test_ds,  batch_size=batch_size,\n",
    "                                       shuffle=False, num_workers=0, pin_memory=True, persistent_workers = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20966853d641694",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:32:21.645520Z",
     "start_time": "2025-05-09T14:32:20.723811Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy,\n",
    "    MulticlassF1Score,\n",
    "    MulticlassConfusionMatrix,\n",
    ")\n",
    "\n",
    "NUM_CLASSES = len(train_df[\"label\"].unique())\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    \"acc\"      : MulticlassAccuracy(num_classes=NUM_CLASSES, average=\"micro\"),   \n",
    "    \"f1_macro\" : MulticlassF1Score(num_classes=NUM_CLASSES, average=\"macro\"),\n",
    "    \"f1_weight\": MulticlassF1Score(num_classes=NUM_CLASSES, average=\"weighted\"),\n",
    "    \"top3\"     : MulticlassAccuracy(num_classes=NUM_CLASSES, top_k=3),           \n",
    "    \"cm\"       : MulticlassConfusionMatrix(num_classes=NUM_CLASSES, normalize=None),\n",
    "}\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "for m in metrics.values():\n",
    "    m.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6983c56aba7c59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:32:24.592071Z",
     "start_time": "2025-05-09T14:32:24.587743Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2874c83d706cfe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:32:26.423633Z",
     "start_time": "2025-05-09T14:32:26.419211Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e079c8415a4289",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:32:33.373242Z",
     "start_time": "2025-05-09T14:32:33.307999Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_one_epoch(ml_model, dl, optimizer, scheduler, device):\n",
    "    ml_model.fit_data()\n",
    "    run_loss = 0.0\n",
    "    for xb, yb in tqdm(dl, leave=False):\n",
    "        xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        preds = ml_model(xb)\n",
    "        loss = F.cross_entropy(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        run_loss += loss.item() * xb.size(0)\n",
    "    if scheduler: scheduler.step()\n",
    "    return run_loss / len(dl.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(ml_model, dl, device):\n",
    "    for m in metrics.values():          \n",
    "        m.reset()\n",
    "\n",
    "    ml_model.eval()\n",
    "    run_loss = 0.0\n",
    "    for xb, yb in dl:                   \n",
    "        xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
    "        logits = ml_model(xb)\n",
    "        run_loss += F.cross_entropy(logits, yb, reduction=\"sum\").item()\n",
    "        for m in metrics.values():      \n",
    "            m.update(logits, yb)\n",
    "\n",
    "    \n",
    "    res = {\"loss\": run_loss / len(dl.dataset)}\n",
    "    for k, m in metrics.items():\n",
    "        res[k] = m.compute().cpu().numpy() if k == \"cm\" else m.compute().item()\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66d099e58d451be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:39:04.343824Z",
     "start_time": "2025-05-09T14:32:45.627855Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "cnn = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "cnn.fc = nn.Linear(cnn.fc.in_features, NUM_CLASSES)\n",
    "cnn = cnn.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(cnn.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=1e-3,\n",
    "    steps_per_epoch=len(train_dl), epochs=15\n",
    ")\n",
    "\n",
    "for epoch in range(15):\n",
    "    t_loss = train_one_epoch(cnn, train_dl, optimizer, scheduler, device)\n",
    "    val_stats = evaluate(cnn, val_dl, device)\n",
    "    print(\n",
    "        f\"[{epoch+1:02d}] \"\n",
    "        f\"loss_tr={t_loss:.3f} | loss_val={val_stats['loss']:.3f} | \"\n",
    "        f\"Acc={val_stats['acc']:.3%} | \"\n",
    "        f\"F1(ma)={val_stats['f1_macro']:.3%} | F1(we)={val_stats['f1_weight']:.3%} | \"\n",
    "        f\"Top-3={val_stats['top3']:.3%}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13f260432233cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:46:30.256634Z",
     "start_time": "2025-05-09T14:39:21.155988Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "\n",
    "vit = vit_b_16(weights=ViT_B_16_Weights.DEFAULT)\n",
    "vit.heads.head = nn.Linear(vit.heads.head.in_features, NUM_CLASSES)\n",
    "vit = vit.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(vit.parameters(), lr=5e-5, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "for epoch in range(5):\n",
    "    t_loss = train_one_epoch(vit, train_dl, optimizer, scheduler, device)\n",
    "    val_stats = evaluate(vit, val_dl, device)\n",
    "    print(\n",
    "        f\"[{epoch+1:02d}] \"\n",
    "        f\"loss_tr={t_loss:.3f} | loss_val={val_stats['loss']:.3f} | \"\n",
    "        f\"Acc={val_stats['acc']:.3%} | \"\n",
    "        f\"F1(ma)={val_stats['f1_macro']:.3%} | F1(we)={val_stats['f1_weight']:.3%} | \"\n",
    "        f\"Top-3={val_stats['top3']:.3%}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ac7b4bd6cac12d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:47:30.617133Z",
     "start_time": "2025-05-09T14:47:17.482388Z"
    }
   },
   "outputs": [],
   "source": [
    "test_cnn = evaluate(cnn, test_dl, device)\n",
    "test_vit = evaluate(vit, test_dl, device)\n",
    "\n",
    "def show_cm(cm, title):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(7,6))\n",
    "    plt.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    ticks = range(NUM_CLASSES)\n",
    "    names = sorted(train_df['class'].unique())\n",
    "    plt.xticks(ticks, names, rotation=45, ha=\"right\")\n",
    "    plt.yticks(ticks, names)\n",
    "    plt.ylabel(\"True\"); plt.xlabel(\"Predicted\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"ResNet-18 — eval_data:\")\n",
    "for k in [\"acc\",\"f1_macro\",\"f1_weight\",\"top3\"]:\n",
    "    print(f\"{k}: {test_cnn[k]:.3%}\")\n",
    "show_cm(test_cnn[\"cm\"], \"ResNet-18 — Confusion Matrix\")\n",
    "\n",
    "print(\"\\nViT-B/16 — eval_data:\")\n",
    "for k in [\"acc\",\"f1_macro\",\"f1_weight\",\"top3\"]:\n",
    "    print(f\"{k}: {test_vit[k]:.3%}\")\n",
    "show_cm(test_vit[\"cm\"], \"ViT-B/16 — Confusion Matrix\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7490b923f08249a",
   "metadata": {},
   "source": [
    "# Улучшения бейзлайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4dfdef44449157",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T15:13:14.973842Z",
     "start_time": "2025-05-09T15:13:14.965558Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch, platform, random, time, numpy as np\n",
    "import torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.dataset import DataLoader, WeightedRandomSampler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torchvision.transforms import v2                \n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy,\n",
    "    MulticlassF1Score, MulticlassConfusionMatrix\n",
    ")\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device =\", device)\n",
    "\n",
    "NUM_CLASSES = len(train_df[\"label\"].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bc99a0175c7ad8",
   "metadata": {},
   "source": [
    "### Аугментация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461b2f11be8ee34e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T15:18:34.817687Z",
     "start_time": "2025-05-09T15:18:34.811846Z"
    }
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "train_tfms = v2.Compose([\n",
    "    v2.Resize(int(IMG_SIZE*1.15), antialias=True),\n",
    "    v2.RandomCrop(IMG_SIZE),\n",
    "    v2.RandAugment(num_ops=2, magnitude=7),\n",
    "    v2.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225]),\n",
    "])\n",
    "val_tfms = v2.Compose([\n",
    "    v2.Resize(int(IMG_SIZE*1.15), antialias=True),\n",
    "    v2.CenterCrop(IMG_SIZE),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "train_ds.tfms = train_tfms\n",
    "val_ds.tfms   = val_tfms\n",
    "test_ds.tfms  = val_tfms\n",
    "\n",
    "mixup_fn = v2.MixUp(alpha=0.4, num_classes=NUM_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93693fd7a5bbd7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T15:18:36.699755Z",
     "start_time": "2025-05-09T15:18:36.691680Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_WORKERS = 0\n",
    "BATCH = 32\n",
    "\n",
    "\n",
    "class_cnt = train_df[\"label\"].value_counts().sort_index().values\n",
    "class_w   = 1. / torch.tensor(class_cnt, dtype=torch.float)\n",
    "loss_fn   = nn.CrossEntropyLoss(weight=class_w.to(device),\n",
    "                                label_smoothing=0.1)\n",
    "\n",
    "sample_w = class_w[train_df[\"label\"].values]\n",
    "sampler  = WeightedRandomSampler(sample_w, len(sample_w), replacement=True)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH, sampler=sampler,\n",
    "                      num_workers=NUM_WORKERS, pin_memory=(device.type==\"cuda\"))\n",
    "val_dl   = DataLoader(val_ds,   batch_size=BATCH, shuffle=False,\n",
    "                      num_workers=NUM_WORKERS, pin_memory=(device.type==\"cuda\"))\n",
    "test_dl  = DataLoader(test_ds,  batch_size=BATCH, shuffle=False,\n",
    "                      num_workers=NUM_WORKERS, pin_memory=(device.type==\"cuda\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9a038d445802e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T15:18:38.219486Z",
     "start_time": "2025-05-09T15:18:38.208973Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"acc\"      : MulticlassAccuracy(num_classes=NUM_CLASSES, average=\"micro\").to(device),\n",
    "    \"f1_macro\" : MulticlassF1Score(num_classes=NUM_CLASSES, average=\"macro\").to(device),\n",
    "    \"f1_weight\": MulticlassF1Score(num_classes=NUM_CLASSES, average=\"weighted\").to(device),\n",
    "    \"top3\"     : MulticlassAccuracy(num_classes=NUM_CLASSES, top_k=3).to(device),\n",
    "    \"cm\"       : MulticlassConfusionMatrix(num_classes=NUM_CLASSES).to(device),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e42b3357c71765",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T15:52:27.545993Z",
     "start_time": "2025-05-09T15:52:27.537268Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "def train_one_epoch(ml_model, loader, opt, sch=None):\n",
    "    ml_model.fit_data(); run_loss = 0.0\n",
    "    for xb, yb in tqdm(loader, leave=False):\n",
    "        xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
    "        xb, yb = mixup_fn(xb, yb)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(device_type=\"cuda\"):\n",
    "            preds = ml_model(xb)\n",
    "            loss  = loss_fn(preds, yb)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt); scaler.update()\n",
    "        run_loss += loss.item() * xb.size(0)\n",
    "    if sch: sch.step()\n",
    "    return run_loss / len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(ml_model, loader):\n",
    "    for m in metrics.values(): m.reset()\n",
    "    ml_model.eval(); run_loss = 0.0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        with torch.amp.autocast(device_type=\"cuda\"):\n",
    "            preds = ml_model(xb)\n",
    "            loss  = loss_fn(preds, yb)\n",
    "        run_loss += loss.item() * xb.size(0)\n",
    "        for m in metrics.values(): m.update(preds, yb)\n",
    "    res = {\"loss\": run_loss / len(loader.dataset)}\n",
    "    for k,m in metrics.items():\n",
    "        res[k] = m.compute().cpu().numpy() if k==\"cm\" else m.compute().item()\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804d12e48a856a9d",
   "metadata": {},
   "source": [
    "### resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc8263341ad869e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T16:02:24.116410Z",
     "start_time": "2025-05-09T15:52:29.099910Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import time\n",
    "\n",
    "res = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "res.fc = nn.Linear(res.fc.in_features, NUM_CLASSES)\n",
    "res = res.to(device)\n",
    "\n",
    "opt_res = torch.optim.AdamW(res.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "sch_res = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(opt_res, T_0=10)\n",
    "\n",
    "for epoch in range(15):\n",
    "    t0 = time.time()\n",
    "    loss_tr = train_one_epoch(res, train_dl, opt_res, sch_res)\n",
    "    val     = evaluate(res, val_dl)\n",
    "    print(\n",
    "        f\"[{epoch:02d}] \"\n",
    "        f\"loss_tr={loss_tr:.3f} | loss_val={val['loss']:.3f} | \"\n",
    "        f\"Acc={val['acc']:.3%} | \"\n",
    "        f\"F1(ma)={val['f1_macro']:.3%} | F1(we)={val['f1_weight']:.3%} | \"\n",
    "        f\"Top-3={val['top3']:.3%} | time={time.time()-t0:.1f}s\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa60f6a54bc661b1",
   "metadata": {},
   "source": [
    "### ViT-B/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7099e06d601473cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T16:23:33.691193Z",
     "start_time": "2025-05-09T16:02:29.246856Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "import time\n",
    "\n",
    "vit = vit_b_16(weights=ViT_B_16_Weights.DEFAULT)\n",
    "vit.heads.head = nn.Linear(vit.heads.head.in_features, NUM_CLASSES)\n",
    "vit = vit.to(device)\n",
    "\n",
    "opt_vit = torch.optim.AdamW(vit.parameters(), lr=5e-5, weight_decay=1e-4)\n",
    "sch_vit = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(opt_vit, T_0=10)\n",
    "\n",
    "for epoch in range(15):\n",
    "    t0 = time.time()\n",
    "    loss_tr = train_one_epoch(vit, train_dl, opt_vit, sch_vit)\n",
    "    val     = evaluate(vit, val_dl)\n",
    "    print(\n",
    "        f\"[{epoch:02d}] \"\n",
    "        f\"loss_tr={loss_tr:.3f} | loss_val={val['loss']:.3f} | \"\n",
    "        f\"Acc={val['acc']:.3%} | \"\n",
    "        f\"F1(ma)={val['f1_macro']:.3%} | F1(we)={val['f1_weight']:.3%} | \"\n",
    "        f\"Top-3={val['top3']:.3%} | time={time.time()-t0:.1f}s\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7af1416dda3a05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T16:30:40.590756Z",
     "start_time": "2025-05-09T16:30:29.920777Z"
    }
   },
   "outputs": [],
   "source": [
    "test_res_aug = evaluate(res, test_dl)\n",
    "test_vit_aug = evaluate(vit, test_dl)\n",
    "\n",
    "\n",
    "def show_cm(cm, title):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    ticks  = range(NUM_CLASSES)\n",
    "    names  = sorted(train_df[\"class\"].unique())\n",
    "    plt.xticks(ticks, names, rotation=45, ha=\"right\")\n",
    "    plt.yticks(ticks, names)\n",
    "    plt.ylabel(\"True\"); plt.xlabel(\"Predicted\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "\n",
    "print(\"ResNet-18 + aug — eval_data:\")\n",
    "for k in [\"acc\", \"f1_macro\", \"f1_weight\", \"top3\"]:\n",
    "    print(f\"{k:9s}: {test_res_aug[k]:.3%}\")\n",
    "show_cm(test_res_aug[\"cm\"], \"ResNet-18 + aug — Confusion Matrix\")\n",
    "\n",
    "print(\"\\nViT-B/16 + aug — eval_data:\")\n",
    "for k in [\"acc\", \"f1_macro\", \"f1_weight\", \"top3\"]:\n",
    "    print(f\"{k:9s}: {test_vit_aug[k]:.3%}\")\n",
    "show_cm(test_vit_aug[\"cm\"], \"ViT-B/16 + aug — Confusion Matrix\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346f42448b559d78",
   "metadata": {},
   "source": [
    "#### Сравнивая с обыным бейзлайном, как будто ситуация осталась примерно такая же."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
